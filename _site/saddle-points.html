

 <!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
    
    
    
    
    <title>On Saddle Points: a painless tutorial | Cheer ML</title>
    

    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Jun Lu, Yixuan Hu">
    

    
    <!--<%- open_graph({twitter_id: theme.author.twitter, google_plus: theme.author.google_plus}) %>-->
    
    <meta name="description" content="page.description">
    
    <meta property="og:type" content="article">
    
    <meta property="og:title" content="On Saddle Points: a painless tutorial">
    <meta property="og:url" content="/saddle-points">
    <meta property="og:site_name" content="Cheer ML">
    <meta property="og:description" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="On Saddle Points: a painless tutorial">
    <meta name="twitter:description" content="page.description">
    <meta name="twitter:creator" content="@">
    <link rel="publisher" href="">

    
    <link rel="alternative" href="/atom.xml" title="Cheer ML" type="application/atom+xml">
    
    
    <link rel="icon" href="/assets/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/assets/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/assets/img/jacman.jpg">
    

    <link rel="stylesheet" href="/assets/css/style.css" type="text/css">
    <link rel="stylesheet" href="/assets/css/highlight.css" type="text/css">
</head>

  <body>
    <header>
        <div>
		    
			<div id="imglogo">
				<a href="/"><img src="/assets/img/logo.png" alt="Cheer ML" title="Cheer ML"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Cheer ML">Cheer ML</a></h1>
				<!-- <h2 class="blog-motto">the essence of machine leaerning</h2> -->
				<h2 class="blog-motto">the essence of ma<font color="black">ch</font>ine l<font color="black">e</font>a<font color="black">er</font>ning</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:">
					</form>
					
					</li>
				</ul>
			</nav>	
</div>
    </header>
    <div id="container">
      



<div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
	<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/saddle-points" title="On Saddle Points: a painless tutorial" itemprop="url">On Saddle Points: a painless tutorial</a>
  </h1>
  <p class="article-author">By
    
		<a href="http://www.junlulocky.com" title="Jun Lu, Yixuan Hu" target="_blank" itemprop="author">Jun Lu</a>
		
  <p class="article-time">
    <time datetime="2016-09-07 00:00:00 +0200" itemprop="datePublished"> Published 2016-09-07</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article toc-content" style="display: none;">
		
			<!--<%- toc(item.content) %>-->
		
		</div>
		
		<p>Are we really stuck in the local minima rather than anything else?</p>

<h2 id="different-types-of-critical-points">Different types of critical points</h2>
<hr />

<div class="fig figcenter fighighlight">
  <img src="/assets/blog/updatemethods/minmaxsaddle.png" width="100%" />
  <div class="figcaption">
    Various Types of Critical Points. Source: Rong Ge's blog.
  </div>
</div>
<hr />

<p>To minimize the function \(f:\mathbb{R}^n\to \mathbb{R}\), the most popular approach is to follow the opposite direction of the gradient \(\nabla f(x)\) (for simplicity, all functions we talk about are infinitely differentiable), that is,</p>

<script type="math/tex; mode=display">y = x - \eta \nabla f(x),</script>

<p>Here \(\eta\) is a small step size. This is the <em>gradient descent</em> algorithm.</p>

<p>Whenever the gradient \(\nabla f(x)\) is nonzero, as long as we choose a small enough \(\eta\), the algorithm is guaranteed to make <em>local</em> progress. When the gradient \(\nabla f(x)\) is equal to \(\vec{0}\), the point is called a <strong>critical point</strong>, and gradient descent algorithm will get stuck. For (strongly) convex functions, there is a unique <em>critical point</em> that is also the <em>global minimum</em>.</p>

<p>However, this is not always this case. All critical points of \( f(x) \) can be further characterized by the curvature of the function in its vicinity, especially described by it’s eigenvalues of the Hessian matrix. Here I describe three possibilities as the figure above shown:</p>

<ul>
  <li>If all eigenvalues are non-zero and positive, then the critical point is a local minimum.</li>
  <li>If all eigenvalues are non-zero and negative, then the critical point is a local maximum.</li>
  <li>If the eigenvalues are non-zero, and both positive and negative eigenvalues exist, then the critical point is a saddle point.</li>
</ul>

<p>The proof of the above three possibilities can be shown from the reparametrization of the space of Hessian matrix. The Taylor expansion is given by(first order derivative vanishes):</p>

<script type="math/tex; mode=display">f(x+\Delta x) = f(x) + \frac{1}{2} (\Delta x)^T \mathbf{H} \Delta x \,\,\,\, -----  \,\,\,(1)</script>

<p>And assume \(\mathbf{e_1}, \mathbf{e_2}, …, \mathbf{e_n}\) are the eigenvectors and \(\lambda_1, \lambda_2, …, \lambda_n\) are the eigenvalues correspondingly. We can make the reparametrization of the space by:</p>

<script type="math/tex; mode=display">\Delta v = \frac{1}{2} \begin{bmatrix} \mathbf{e_1}^T\\ ... \\ \mathbf{e_n}^T \end{bmatrix} \Delta x</script>

<p>Then combined with Taylor expansion, we can get the following equation:</p>

<script type="math/tex; mode=display">f(x+ \Delta x) = f(x)+\frac{1}{2} \sum_{i=1}^n \lambda_i(\mathbf{e_i}^T \Delta x)^2 = f(x) + \sum_{i=1}^n \lambda_i \Delta \mathbf{v_i}^2</script>

<p>For the proof of the above equation, you may need to look at <a href="https://inst.eecs.berkeley.edu/~ee127a/book/login/l_sym_sed.html">Spectrum Theorem</a>, which is related to the eigenvalues and eigenvectors of symmetric matrices.</p>

<p>From this equation, all the three scenarios for critical points are self-explained.</p>

<h2 id="first-order-method-to-escape-from-saddle-point">First order method to escape from saddle point</h2>
<p>A <a href="http://www.offconvex.org/2016/03/22/saddlepoints/">post</a> by Rong Ge introduced a first order method to escape from saddle point. He claimed that saddle points are very <em>unstable</em>: if we put a ball on a saddle point, then slightly perturb it, the ball is likely to fall to a local minimum, especially when the second order term \(\frac{1}{2} (\Delta x)^T \mathbf{H} \Delta x\) is significantly smaller than 0(there is a steep direction where the function value decrease, and assume we are looking for local minimum), which is called a <em>Strict Saddle Function</em> in Rong Ge’s post. In this case we can use <em>noisy gradient descent</em>:</p>

<blockquote>
  <p>\(y = x - \eta \nabla f(x) + \epsilon.\)</p>
</blockquote>

<p>where \(\epsilon\)  is a noise vector that has mean \(\mathbf{0}\). Actually, it is the basic idea of <em>stochastic gradient descent</em>, which uses the gradient of a mini batch rather than the true gradient. However, the drawback of the stochastic gradient descent is not the direction, but the size of the step along each eigenvector. The step, along any direction \(\mathbf{e_i}\), is given by \(-\lambda_i \Delta \mathbf{v_i}\), when the steps taken in the direction with small absolute value of eigenvalues, the step is small. To be more concrete, an example that the curvature of the error surface may not be the same in all directions. If there is a long and narrow valley in the error surface, the component of the gradient in the direction that points along base of the valley is very small while the component perpendicular to the valley walls is quite large even though we have to move a long distance along the base and a small distance perpendicular to the walls. This phenomenon can be seen as the following figure:</p>

<hr />

<div class="fig figcenter fighighlight">
  <img src="/assets/blog/updatemethods/without_momentum.png" width="70%" />
  <div class="figcaption">
    SGD optimization routes
  </div>
</div>
<hr />

<p>We normally move by making a step that is some constant times the negative gradient rather than a step of constant length in the direction of the negative gradient. This means that in steep regions (where we have to be careful not to make our steps too large), we move quickly, and in shallow regions (where we need to move in big steps), we move slowly.</p>

<h2 id="newton-methods">Newton methods</h2>
<p>To look at the detail of newton methods, you can follow the proof shown in (Sam Roweis’s) in the reference list. The newton method solves the slowness problem by rescaling the gradients in each direction with the inverse of the corresponding eigenvalue, yielding the step \(-\Delta \mathbf{v_i}\)(because \(\frac{1}{\lambda_i}\mathbf{e_i} = \mathbf{H}^{-1}\mathbf{e_i}  \) ). However, this approach can result in moving in the wrong direction when the eigenvalue is negative. The newton step moves along the eigenvector in a direction <strong>opposite</strong> to the gradient descent step, thus increase the error.</p>

<p>From the idea of Levenberg gradient descent method, we can use damping, in which case we remove negative curvature by adding a constant \(\alpha\) to its diagonal. Informally, \(x^{k+1} = x^{k} - (\mathbf{H}+\alpha \mathbf{I})^{-1} \mathbf{g_k}\). We can view \(\alpha\) as the tradeoff between newton methods and gradient descent. When \(\alpha\) is small, it is closer to newton method, when \(\alpha\) is large, it is closer to gradient descent. In this case, we get the step \(-\frac{\lambda_i}{\lambda_i + \alpha}\Delta \mathbf{v_i}\). Therefore, obviously, the drawback of damping newton method is that it potentially has small step size in many eigen-directions incurred by large damping factor \(\alpha\).</p>

<h2 id="saddle-free-newton-method">Saddle free newton method</h2>
<p>(Dauphin et al., 2014) introduced a method called saddle free newton method, which is a modified version of trust region approach. It minimizes first-order Taylor expansion constraint by the distance between first-order Taylor expansion and second-order Taylor expansion. By this constraint, unlike gradient descent, it can move further in the directions of low curvature; and move less in the directions of high curvature. I recommend you to read this paper throughly.</p>

<h2 id="future-post">Future post</h2>
<p>I have talked about degenerate critical point in this post， where there are only positive and zero eigenvalues in the Hessian matrix.</p>

<h2 id="marks">Marks</h2>

<p>The slides for the talk of this blog can be found at <a href="http://www.junlulocky.com/assets/talks/2016onsaddlepoints.pdf">Link</a>. Contact me if the link is not working.</p>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://inst.eecs.berkeley.edu/~ee127a/book/login/l_sym_sed.html">Berkeley Optimization Models: Spectral Theorem</a></li>
  <li>Dauphin, Yann N., et al. <em>Identifying and attacking the saddle point problem in high-dimensional non-convex optimization.</em> Advances in neural information processing systems. 2014.</li>
  <li><a href="https://www.cs.nyu.edu/~roweis/notes/lm.pdf">Sam Roweis’s note on Levenberg-Marquardt Optimization</a></li>
  <li>Rong Ge, <em>Escaping from Saddle Points</em>, Off the convex path blog, 2016</li>
  <li>Benjamin Recht, <em>Saddles Again</em>, Off the convex path blog, 2016</li>
</ul>

  
	</div>
	<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <!--
  <%- list_categories(item.categories, {
      show_count: false,
      class: 'article-category',
      style: 'none',
      separator: '►'
  }) %>
  -->
  
  <a class="article-category-link" href="/categories/#Machine Learning">Machine Learning</a>
  
</div>


  <div class="article-tags">
  <!--
  <% var tags = [];
    item.tags.forEach(function(tag){
      tags.push('<a href="' + config.root + tag.path + '">' + tag.name + '</a>');
    }); %>-->
  <span></span> <!--<%- tags.join('') %>-->
  
  
  <a href="/tags/#Learning theory">Learning theory</a>
  
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://localhost:4000/saddle-points" data-title="On Saddle Points: a painless tutorial | Cheer ML" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>   
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/normalizations-in-neural-networks" title="Normalizations in Neural Networks">
  <strong>Prev: </strong><br/>
  <span>
  Normalizations in Neural Networks</span>
</a>
</div>


<div class="next">
<a href="/bias-variance"  title="Bias-variance decomposition in a nutshell">
 <strong>Next: </strong><br/> 
 <span>Bias-variance decomposition in a nutshell
</span>
</a>
</div>

</nav>

	

</div>  

      
      
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside toc-content">
 
 <!--<%- toc(item.content) %>-->
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">


  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/#Announcement" title="Announcement">Announcement<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/#Machine Learning" title="Machine Learning">Machine Learning<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/#Deep Learning" title="Deep Learning">Deep Learning<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/#Theory" title="Theory">Theory<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/#NLP" title="NLP">NLP<sup>2</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/#resources" title="resources">resources<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/#jekyll" title="jekyll">jekyll<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/#Learning theory" title="Learning theory">Learning theory<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/#Deep Learning" title="Deep Learning">Deep Learning<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/#Systems" title="Systems">Systems<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/#Theory" title="Theory">Theory<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/#Machine Learning" title="Machine Learning">Machine Learning<sup>2</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            <a href="http://www.junlulocky.com" target="_blank" title="Jun Lu's website">Jun Lu's website</a>
          </li>
        
          <li>
            <a href="http://yeephycho.github.io/" target="_blank" title="Yixuan Hu's website">Yixuan Hu's website</a>
          </li>
        
          <li>
            <a href="https://github.com/IamTao" target="_blank" title="Tao Lin's website">Tao Lin's website</a>
          </li>
        
          <li>
            <a href="https://ovss.github.io" target="_blank" title="Junxiong Wang's website">Junxiong Wang's website</a>
          </li>
        
          <li>
            <a href="https://www.linkedin.com/in/geelon" target="_blank" title="Aaron Geelon So's website">Aaron Geelon So's website</a>
          </li>
        

    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, we are machine learning lovers. <br/>
			This is our blog, believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
	<!--
			<%  Array.prototype.S=String.fromCharCode(2);
			  Array.prototype.in_array=function(e){
    			var r=new RegExp(this.S+e+this.S);
    			return (r.test(this.S+this.join(this.S)+this.S));
				};
				var cc = new Array('by','by-nc','by-nc-nd','by-nc-sa','by-nd','by-sa','zero'); %>
		<% if (cc.in_array(theme.creative_commons) ) { %>
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/<%= theme.creative_commons %>/4.0" class="cc-opacity" target="_blank">
            <img src="<%- config.root %>img/cc-<%= theme.creative_commons %>.svg" alt="Creative Commons" />
          </a>
        </div>
    <% } %>
				-->

		<p class="copyright">
		Powered by <a href="http://jekyllrb.com" target="_blank" title="jekyll">jekyll</a> and Theme by <a href="#" target="_blank" title="Jacman">Jacman</a> © 2017
		
		<a href="about" target="_blank" title="Jun Lu, Yixuan Hu">Jun Lu, Yixuan Hu</a>
		
		
		</p>
</div>
</footer>
    <script src="/assets/js/jquery-2.0.3.min.js"></script>
<script src="/assets/js/jquery.imagesloaded.min.js"></script>
<script src="/assets/js/gallery.js"></script>
<script src="/assets/js/jquery.qrcode-0.12.0.min.js"></script>
<script src="/assets/js/toc.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
      
    }
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  $('#toc.toc-aside').toc({
    title: "Contents",
    showEffect: "none"
  });
  $('#toc.toc-article').toc({
    title: "Contents",
    showEffect: "show",
    showSpeed: 0
  });
});
</script>



<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>



<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#nothing"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
/*
  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      //$('.hoverqrcode').hide();
  });
  */
});   
</script>





<!--

-->




<link rel="stylesheet" href="/assets/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/assets/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      if ($(this).hasClass('emoji')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>


<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/assets/img/scrollup.png"/></a>
	</div>
	<script src="/assets/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
      processEscapes: true
    },
    messageStyle: "none",
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<!--<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script> 

<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->
  </body>
</html>


